# Papers 2025

## Large Language Diffusion Models
- [LLaDA](https://arxiv.org/abs/2502.09992) -> Diffusion models can perform as good or outperform Auto-Regressive LLMs with similar compute!
- [d1](https://arxiv.org/abs/2504.12216) -> diffuGRPO: method to add reasoning capabilities to diffusion LLMs. 

## Reasoning Models / RL
- [DeepSeekMath](https://arxiv.org/abs/2402.03300) -> GRPO was introduced here, interesting data collection pipeline
- 

## Transformer: Architecture and/or Training
- [Attention sinks in Transformers](https://arxiv.org/abs/2504.02732) -> analysis of phenomenon, where transformers attend a lot to the first token in sequence
- [DeepSeekV3 innovations](https://arxiv.org/pdf/2503.11486) -> List of new tricks: key-value joint embedding, expert segmentation and shared expert
- [ByteLatentTransformer](https://arxiv.org/abs/2412.09871) -> Transformer that matches performance of token-based models, but encoding bytes

## not from 2025 but read first time this year...
- [PagedAttention from vLLM](https://arxiv.org/abs/2309.06180) -> KV-Cache implementation that was used to build vLLM on top
