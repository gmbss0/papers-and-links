# Papers 2025

## Reasoning Models / RL
- [DeepSeekMath](https://arxiv.org/abs/2402.03300) -> GRPO was introduced here, interesting data collection pipeline
- 

## Transformer: Architecture and/or Training
- [Attention sinks in Transformers](https://arxiv.org/abs/2504.02732) -> analysis of phenomenon, where transformers attend a lot to the first token in sequence
- [DeepSeekV3 innovations](https://arxiv.org/pdf/2503.11486) -> List of new tricks: key-value joint embedding, expert segmentation and shared expert
